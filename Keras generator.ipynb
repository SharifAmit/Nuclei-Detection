{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "Y_train = np.load('Y_train.npy')\n",
    "with open('sizes_test.pkl', 'rb') as f:\n",
    "    sizes_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "\n",
    "\n",
    "def Unet(img_size):\n",
    "    inputs = Input((img_size, img_size, 3))\n",
    "    s = Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def generator(xtr, xval, ytr, yval, batch_size):\n",
    "    data_gen_args = dict(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         rotation_range=90.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.1)\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    image_datagen.fit(xtr, seed=7)\n",
    "    mask_datagen.fit(ytr, seed=7)\n",
    "    image_generator = image_datagen.flow(xtr, batch_size=batch_size, seed=7)\n",
    "    mask_generator = mask_datagen.flow(ytr, batch_size=batch_size, seed=7)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "    val_gen_args = dict()\n",
    "    image_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "    mask_datagen_val = ImageDataGenerator(**val_gen_args)\n",
    "    image_datagen_val.fit(xval, seed=7)\n",
    "    mask_datagen_val.fit(yval, seed=7)\n",
    "    image_generator_val = image_datagen_val.flow(xval, batch_size=batch_size, seed=7)\n",
    "    mask_generator_val = mask_datagen_val.flow(yval, batch_size=batch_size, seed=7)\n",
    "    val_generator = zip(image_generator_val, mask_generator_val)\n",
    "\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec))\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "101/100 [==============================] - 110s 1s/step - loss: -0.5109 - mean_iou: 0.5597 - val_loss: -0.7783 - val_mean_iou: 0.6959\n",
      "Epoch 2/50\n",
      "101/100 [==============================] - 95s 941ms/step - loss: -0.7816 - mean_iou: 0.7399 - val_loss: -0.8190 - val_mean_iou: 0.7708\n",
      "Epoch 3/50\n",
      "101/100 [==============================] - 96s 946ms/step - loss: -0.8116 - mean_iou: 0.7882 - val_loss: -0.8168 - val_mean_iou: 0.8024\n",
      "Epoch 4/50\n",
      "101/100 [==============================] - 96s 946ms/step - loss: -0.8235 - mean_iou: 0.8121 - val_loss: -0.8415 - val_mean_iou: 0.8204\n",
      "Epoch 5/50\n",
      "101/100 [==============================] - 96s 947ms/step - loss: -0.8276 - mean_iou: 0.8266 - val_loss: -0.8206 - val_mean_iou: 0.8318\n",
      "Epoch 6/50\n",
      "101/100 [==============================] - 95s 945ms/step - loss: -0.8359 - mean_iou: 0.8363 - val_loss: -0.8443 - val_mean_iou: 0.8403\n",
      "Epoch 7/50\n",
      "101/100 [==============================] - 95s 944ms/step - loss: -0.8357 - mean_iou: 0.8435 - val_loss: -0.8420 - val_mean_iou: 0.8464\n",
      "Epoch 8/50\n",
      "101/100 [==============================] - 95s 940ms/step - loss: -0.8420 - mean_iou: 0.8490 - val_loss: -0.8539 - val_mean_iou: 0.8514\n",
      "Epoch 9/50\n",
      "101/100 [==============================] - 95s 943ms/step - loss: -0.8433 - mean_iou: 0.8535 - val_loss: -0.8581 - val_mean_iou: 0.8554\n",
      "Epoch 10/50\n",
      "101/100 [==============================] - 95s 936ms/step - loss: -0.8457 - mean_iou: 0.8571 - val_loss: -0.8535 - val_mean_iou: 0.8587\n",
      "Epoch 11/50\n",
      "101/100 [==============================] - 96s 949ms/step - loss: -0.8453 - mean_iou: 0.8601 - val_loss: -0.8519 - val_mean_iou: 0.8615\n",
      "Epoch 12/50\n",
      "101/100 [==============================] - 95s 940ms/step - loss: -0.8458 - mean_iou: 0.8627 - val_loss: -0.8540 - val_mean_iou: 0.8638\n",
      "Epoch 13/50\n",
      "101/100 [==============================] - 95s 936ms/step - loss: -0.8499 - mean_iou: 0.8649 - val_loss: -0.8439 - val_mean_iou: 0.8659\n",
      "Epoch 14/50\n",
      "101/100 [==============================] - 94s 934ms/step - loss: -0.8519 - mean_iou: 0.8669 - val_loss: -0.8577 - val_mean_iou: 0.8679\n",
      "Epoch 15/50\n",
      "101/100 [==============================] - 95s 940ms/step - loss: -0.8521 - mean_iou: 0.8687 - val_loss: -0.8606 - val_mean_iou: 0.8696\n",
      "Epoch 16/50\n",
      "101/100 [==============================] - 95s 940ms/step - loss: -0.8511 - mean_iou: 0.8703 - val_loss: -0.8556 - val_mean_iou: 0.8710\n",
      "Epoch 17/50\n",
      "101/100 [==============================] - 95s 938ms/step - loss: -0.8549 - mean_iou: 0.8718 - val_loss: -0.8550 - val_mean_iou: 0.8724\n",
      "Epoch 18/50\n",
      "101/100 [==============================] - 95s 943ms/step - loss: -0.8551 - mean_iou: 0.8731 - val_loss: -0.8610 - val_mean_iou: 0.8737\n",
      "Epoch 19/50\n",
      "101/100 [==============================] - 94s 935ms/step - loss: -0.8552 - mean_iou: 0.8743 - val_loss: -0.8609 - val_mean_iou: 0.8748\n",
      "Epoch 20/50\n",
      "101/100 [==============================] - 95s 938ms/step - loss: -0.8574 - mean_iou: 0.8754 - val_loss: -0.8583 - val_mean_iou: 0.8759\n",
      "Epoch 21/50\n",
      "101/100 [==============================] - 95s 941ms/step - loss: -0.8566 - mean_iou: 0.8764 - val_loss: -0.8665 - val_mean_iou: 0.8769\n",
      "Epoch 22/50\n",
      "101/100 [==============================] - 94s 935ms/step - loss: -0.8577 - mean_iou: 0.8774 - val_loss: -0.8648 - val_mean_iou: 0.8778\n",
      "Epoch 23/50\n",
      "101/100 [==============================] - 95s 938ms/step - loss: -0.8581 - mean_iou: 0.8783 - val_loss: -0.8588 - val_mean_iou: 0.8787\n",
      "Epoch 24/50\n",
      "101/100 [==============================] - 95s 938ms/step - loss: -0.8603 - mean_iou: 0.8791 - val_loss: -0.8644 - val_mean_iou: 0.8795\n",
      "Epoch 25/50\n",
      " 23/100 [=====>........................] - ETA: 1:12 - loss: -0.8549 - mean_iou: 0.8796"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img_size = 256\n",
    "    batch_size = 32\n",
    "    train_path = 'stage1_train/'\n",
    "    test_path = 'stage1_test/'\n",
    "    \n",
    "    xtr, xval, ytr, yval = train_test_split(X_train, Y_train, test_size=0.1, random_state=7)\n",
    "    train_generator, val_generator = generator(xtr, xval, ytr, yval, batch_size)\n",
    "    \n",
    "    model = Unet(img_size)\n",
    "    model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[mean_iou])\n",
    "    \n",
    "    model.fit_generator(train_generator, steps_per_epoch=len(xtr)/6, epochs=50,\n",
    "                        validation_data=val_generator, validation_steps=len(xval)/batch_size)\n",
    "    \n",
    "    preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "    preds_test_upsampled = []\n",
    "    for i in range(len(preds_test)):\n",
    "        preds_test_upsampled.append(cv2.resize(preds_test[i], \n",
    "                                           (sizes_test[i][1], sizes_test[i][0])))\n",
    "        \n",
    "    test_ids = next(os.walk(test_path))[1]\n",
    "    new_test_ids = []\n",
    "    rles = []\n",
    "    for n, id_ in enumerate(test_ids):\n",
    "        rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "        rles.extend(rle)\n",
    "        new_test_ids.extend([id_] * len(rle))\n",
    "    sub = pd.DataFrame()\n",
    "    sub['ImageId'] = new_test_ids\n",
    "    sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "    sub.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
